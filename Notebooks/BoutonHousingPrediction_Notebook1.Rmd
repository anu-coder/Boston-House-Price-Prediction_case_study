---
title: "Boston House Price Prediction"
subtitle: "Notebook 1: Regression models"
author:
  name: "Anurima Dey"
date: 28-february-2020
output:
html_document:
df_print: paged
---

## Purpose of the project: 

This notebook contains the regression models for the House Price Prediction.
We proceed stepwise.

### Step 1: Obtaining and cleaning the data. 


The data is obtained from kaggle website. <br>The displayed are the __features__ of the dataset.  


1. CRIM     – per capita crime rate by town <br>
2. ZN       – proportion of residential land zoned for lots over 25,000 sq.ft <br>
3. INDUS    – proportion of non-retail business acres per town <br>
4. CHAS     – Charles River dummy variable (1 if tract bounds river; else 0) <br>
5. NOX      – nitric oxides concentration (parts per 10 million) <br>
6. RM       – average number of rooms per dwelling <br>
7. AGE      – proportion of owner-occupied units built prior to 1940 <br>
8. DIS      – weighted distances to five Boston employment centres<br>
9. RAD      – index of accessibility to radial highways <br>
10. TAX      – full-value property-tax rate per $10,000 <br>
11. PTRATIO  – pupil-teacher ratio by town <br>
12. B        – 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town <br>
13. LSTAT    – % lower status of the population <br>
14. MEDV     – Median value of owner-occupied homes in $1000’s

Read the dataset as a dataframe using read.table. After loading and cleaning the data set looks like the following.

```{r}
data.file <- normalizePath("../Data/housing.csv") 
Bhousing <- read.table(data.file, header = FALSE, sep= "")
column_names=c('CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 
                'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV')
names(Bhousing)=column_names
head(Bhousing)

```


```{r}
class(Bhousing)
```
Now, let us check and explore the cleaned data frame containing the housing data. The __Bhousing__ R object is of class ‘data.frame’. <br> The __str()__ function displays the structure of an R dataframe.

#### What does __str()__ show:
1. The data type.
2. Name and data types of each column.
3. Some of the observations.

```{r}
str(Bhousing)
```

To get more detailed statistical information from each column, __summary()__ function can be used. It displays the summary statistics like *minimum value, maximum value, median, mean, and the 1st and 3rd quartile* values for each column in our dataset.<br> Summary also provides information about the missing values, if any is present. We see that there are no missing values in any of our variables.

```{r}
summary(Bhousing)
```

We shall base our prediction mainly on the attribute MEDV (median value of the owner occupied homes) and also on other attributes that are strongly correlated to it. For the given variables and our intuition, we can feel that mnainly, DIS, RAD, LSTAT, NOX, INDUS, CRIM, TAX should have some effect on the variable MEDV. But we shall try to find out all the different types of dependencies in the next section. 

### Step 2: Data Exploration and Data Visualization

 
```{r}
library(ggplot2)

ggplot(data= Bhousing, mapping = aes(MEDV))+ 
  geom_histogram(aes(y=..density..), binwidth=2, color = "red", fill= "blue")+
  geom_density(size= 1 )+
  labs(title = "Histogram of MEDV", x= "Median Value", ylab= "count" )+
  scale_x_continuous(breaks = seq(0,50,10), labels = function(x){paste0(x,'K')})+
  scale_y_continuous(breaks = seq(0,80,10))
  
```

First thing, we try to find out density and the spread of MEDV. The previous graph shows that median value is right skewed, showing the presence of extreme values. The boxplot in the next graph also shows the same So it will be useful if we consider the log transformation to normalise the variance. 

```{r}
ggplot(data=Bhousing, aes(MEDV))+
  geom_boxplot(color="red", fill= "steelblue")
```

Next based on our intuitions we would like to see how certain variables are related to each other. as mentioned previously we shall try to see the ealtion between *DIS, RAD, LSTAT, NOX, INDUS, CRIM, TAX* variables, for this we simply plot the elements. 


```{r}
library(caret)
library(ggplot2)

featurePlot(x = Bhousing[ ,c(1,3,5,6,8,13)], 
            y = Bhousing$MEDV, 
            plot = "scatter",
            type = c("p", "smooth"),
            span = .5,
            layout = c(3, 2))

```

We see that MEDV has more or less a positive or negetive correlation with all other variables we have plotted. 

```{r}
plot(Bhousing[,c(1,6,8,11,13)])
```

Also another thing that needs to be noticed is that all other variables are also correlated to each other. This gives us an intuition that we can probably apply dimension reducibility techniques i.e. PCA or LDA etc while building a model.

### Step 3: Finding coorelations

Let us now find out the correlation of the MEDV with the other variables. Here MEDV is our dependant variable and the rest of the variables are independent variables.  

```{r}
cor(Bhousing, Bhousing$MEDV)
```

```{r}
rank(cor(Bhousing, Bhousing$MEDV))
```

The above statements show that the most negetively correlated is LSTAT and the most positily correlated is RM. 

You can also get names in order of maximum positive correlation to maximum negative correlation as follows using ```order```:
```{r}
corr <- cor(Bhousing, Bhousing$MEDV)
corr.ord <- order(corr)
rownames(corr)[corr.ord]
```

### Step 4: Feature selection and Data partitioning

Next we create the training and testing dataset. The training dataset will contain 70% of the data and the testing dataset will contain remaining 30% of the data. To do so here we use a library caret, and create data partition using inbuilt functions like createDataPartition. We could otherwise have divided the data frame manually in to first 70% and remaining 30%.   

```{r}
library(caret)
Bhousing.scale=cbind(scale(Bhousing[1:13]), Bhousing[14])
set.seed(10)

inTrain <- createDataPartition(y=Bhousing.scale$MEDV, p=0.70, list= F)
Bhousing.training <- Bhousing.scale[inTrain,]
Bhousing.testing <- Bhousing.scale[-inTrain,]
head(Bhousing.training)
```

We shall now implement various regression models and find the best one. 

Let us first find out the generalised linear Regression model taking, MEDV as the dependant variable and the rest of the dataset as the dependant variable.

### Using REGRESSION 

#### Model 1:

$Y= \alpha + \beta X + \epsilon$  where </br>
$X$: the matrix containing all the independent variables,</br> 
$Y$: the dependant variable MEDV. </br>
$\epsilon$ : residual error.

```{r}
set.seed(10)
lm1=lm(MEDV~., data=Bhousing.training)

sm1=summary(lm1)
sm1
```

Here the p value shows that the beta_ols values of the coefficient are significant. i.e. we can reject the null hypothesis beta_ols=0 in favour of the alternate hypothesis. 

Now on this data we shall be predicting the values of the training data set. 

```{r}
summary(Bhousing.testing$MEDV)
```


```{r}
set.seed(10)
pred.lm1=predict(lm1, newdata= Bhousing.testing)

summary(pred.lm1)
```

The summary show a significant difference in the values of the quartiles. Let us now choose the statistics that we would be using to determine the effeiciency of the model. 

1. The RMSE value: </br>
  
  $RMSE= \sqrt{\frac{\sum(y_{pred}-y_{act})}{n}}$ </br>
  
  The higher lower the valur of the $RMSE$ the better the prediction. 
  
2. Correlation between actual and predicted values, higher correction implies more accuracy. </br>

3. MaxMinAccuracy= $mean(\frac{min(actual_i,pred_i)}{max(actual_i,pred_i)})$, the greater the better. </br>
4. Maximum Absolute Percentage Error (MAPE) : $mean(abs(\frac{pred_i-actual_i}{actual_i}))$, smaller the better.

All this can be manually calculated and compared, for the first model we shall show all of them manually, however from the next onwards we shall be using a package DMwR to find out all the regression errors and the compare among various models.

All the errors that one cand are: </br>
__RMSE__:  Root Mean Squared Error </br>
__MPE__:   Mean Percentage error </br>
__MAPE__:  Mean Absolute Percentage Error </br>
__MSE__:   Mean Squared Error </br>
__RSS__:   Residual sum of Squares </br>
__MAE__:   Mean Absolute Error </br>
__MAAPE__: Mean Arc-tangent Absolute Error </br>


```{r}
actuals_predicts= data.frame(cbind(actuals=Bhousing.testing$MEDV, predicts=pred.lm1))

head(actuals_predicts)

```

```{r}
#error 1: RMSE

RMSE(pred.lm1,Bhousing.testing$MEDV)
```
```{r}
#error 2: correlation percentage

cor(actuals_predicts$actuals, actuals_predicts$predicts)*100 #in percentage
```
```{r}
#error 3: Min_max_accuracy

mean(apply(actuals_predicts, 1, min) / apply(actuals_predicts, 1, max))*100  # in percentage

```

```{r}
#error 4: MAPE
mean(abs((actuals_predicts$predicts - actuals_predicts$actuals))/actuals_predicts$actuals)*100
```

```{r}
#using package DMwR
library(DMwR)
library(grid)
set.seed(10)
regr.eval(actuals_predicts$actuals,actuals_predicts$predicts)

```

#### Regression using inbuilt library "caret"

Now we shall be using k-fold cross validation, the above performance is for this particular model, which may or may not be representative of the entire data set. So we shall carry out rigorous testing by dividing the data set into k folds and each time using one fold for testing and remaining k-1 fold for training. 

The average of your k recorded errors is called the cross-validation error and will serve as your performance metric for the model. 


But here we shall be using a repeated cross validation. </br>
In repeated cross-validation, the cross-validation procedure is repeated n times, yielding n random partitions of the original sample. The n results are again averaged (or otherwise combined) to produce a single estimation.

To do all this we shall use the "caret" library and use a inbuilt method "linear model(lm)" and also use "repeated cross validation". 

First we shall train the model using "repetedcv" using 10 folds and 10 repeats. 


```{r}
library(caret)

set.seed(10)

train_control <- trainControl(method="repeatedcv", number=10, repeats = 10)

model <- train(MEDV~., data=Bhousing.training, trControl=train_control, method="lm")

print(model)
```

The above summary says that: </br>
1. RMSE after 100 times is 4.798 (average of 100) nearly</br>
2. The tuning intercept is kept constant at 1 (TRUE value)

```{r}
names(model)
```

```{r}
model$results
```

```{r}
head(model$resample)
```

The above gives the value at each individual resample.

```{r}
model$finalModel
```

The final model selected has the following coefficients.

```{r}
layout(matrix(c(1,2,3,4),2,2))
plot(model$finalModel)
```

```{r}
set.seed(10)
pred.m1=predict(model, newdata=Bhousing.testing)
summary(pred.m1)
```

```{r}
actuals_predicts= data.frame(cbind(actuals=Bhousing.testing$MEDV, predicts=pred.lm1))

head(actuals_predicts)

```

```{r}
#using package DMwR
library(DMwR)
library(grid)
set.seed(10)
regr.eval(actuals_predicts$actuals,actuals_predicts$predicts)

```

```{r}
plot(density(pred.m1),col="red", 
     main="Predicted Vs observed", xlab="", )
lines(density(Bhousing.testing$MEDV), col="blue") 
```


#### Model 2

$log(Y)=\alpha+\beta X+\epsilon$


```{r}
set.seed(10)
train_control <- trainControl(method="repeatedcv", number=10, repeats = 10)

model <- train(log(MEDV)~., data=Bhousing.training, trControl=train_control, method="lm")

print(model)

```

```{r}
layout(matrix(c(1,2,3,4),2,2))
plot(model$finalModel)
```

```{r}
set.seed(10)
pred.m2=predict(model, newdata=Bhousing.testing)
actuals_predicts= data.frame(cbind(actuals=Bhousing.testing$MEDV, predicts=exp(pred.m2)))

head(actuals_predicts)

```

```{r}
#using package DMwR
library(DMwR)
library(grid)
set.seed(10)
regr.eval(actuals_predicts$actuals,actuals_predicts$predicts)
```
```{r}
plot(density(exp(pred.m2)),col="red", 
     main="Predicted Vs observed", xlab="")
lines(density(Bhousing.testing$MEDV), col="blue") 

```
You can also create a separate function for it
```{r}

compare.dens <- function(v1, v2, legend=c("v1", "v2"), 
                         main=NULL, ...) {

  # check for main
  if (is.null(main)){
    main <- paste(legend, collapse = " vs ")
  }
  
  
  v1.dens <- density(v1) # v1 density
  v2.dens <- density(v2) # v2 density
  
  # Find the max peak of the two
  max.dens <- max(c(v1.dens$y, v2.dens$y))
  
  plot(v1.dens, col="red", xlab="" ,
       ylim = c(0, max.dens), main=main, ...)
  lines(v2.dens, col="blue")
  
  legend("topright",
         legend = legend,
         lty=1,
         col=c("red", "blue"))
  
}


compare.dens(exp(pred.m2), Bhousing.testing$MEDV, legend = c("predicted", "observed"))
```


#### Model 3

$log(MEDV) = DIS+RAD+LSTAT+NOX+INDUS+CRIM+TAX$
$log(Y)=\alpha+\beta X+\epsilon$


```{r}
set.seed(10)
train_control <- trainControl(method="repeatedcv", number=10, repeats = 10)

model <- train(log(MEDV) ~ DIS+RAD+LSTAT+NOX+INDUS+CRIM+TAX, data=Bhousing.testing, trControl=train_control, method="lm")

print(model)

```

```{r}
layout(matrix(c(1,2,3,4),2,2))
plot(model$finalModel)
```


```{r}
set.seed(10)
pred.m2=predict(model, newdata=Bhousing.testing)
actuals_predicts= data.frame(cbind(actuals=Bhousing.testing$MEDV, predicts=exp(pred.m2)))

head(actuals_predicts)

```

```{r}
#using package DMwR
library(DMwR)
library(grid)
set.seed(10)
regr.eval(actuals_predicts$actuals,actuals_predicts$predicts)
```
```{r}
plot(density(exp(pred.m2)),col="red", 
     main="Predicted Vs observed", xlab="", )
lines(density(Bhousing.testing$MEDV), col="blue") 
```

#### Model 4

Let us now apply PCA in this, from the scree plot select the optimised feature and then apply the model.

```{r}
set.seed(10)
Bhousing.pca=cbind(scale(Bhousing[1:3]), scale(Bhousing[5:8]), scale(Bhousing[10:13]))

pc=prcomp(Bhousing.pca, scale=FALSE)
plot(pc)

```

```{r}
dim(Bhousing.pca)
```

```{r}
set.seed(10)
pc.pc1=as.matrix(pc$rotation[,1], nrow=length(pc$rotation[,1]))

pc.pc1
```

```{r}
model4.pc1=Bhousing.pca%*%pc.pc1
dim(model4.pc1)
```

```{r}
set.seed(10)
pc.data=data.frame(pc1=model4.pc1, CHAS=Bhousing$CHAS, RAD=Bhousing$RAD, MEDV=Bhousing$MEDV)
pc.inTrain <- createDataPartition(y=pc.data$MEDV, p=0.70, list= F)
pc.data.training <- pc.data[pc.inTrain,]
pc.data.testing <- pc.data[-pc.inTrain,]
head(pc.data.training)
```


```{r}
set.seed(10)
train_control <- trainControl(method="repeatedcv", number=10, repeats = 10)

model <- train(log(MEDV) ~ pc1, data=pc.data.training, trControl=train_control, method="lm")

print(model)

```

```{r}
layout(matrix(c(1,2,3,4),2,2))
plot(model$finalModel)
```

```{r}
set.seed(10)
pred.m2=predict(model, newdata=pc.data.testing)
actuals_predicts= data.frame(cbind(actuals=pc.data.testing$MEDV, predicts=exp(pred.m2)))

head(actuals_predicts)

```

```{r}
#using package DMwR
library(DMwR)
library(grid)
set.seed(10)
regr.eval(actuals_predicts$actuals,actuals_predicts$predicts)
```

```{r}
plot(density(exp(pred.m2)),col="red", 
     main="Predicted Vs observed", xlab="", )
lines(density(Bhousing.testing$MEDV), col="blue") 
```



Thus comparing the four models we see that the model 2 is the best. However certain tunings can be still carried out in model 4. 

Thank you




